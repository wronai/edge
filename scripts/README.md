# ğŸ”§ Quick Fix Guide - K3s Deployment Issues

## ğŸš¨ Immediate Solution

3 opcje aby szybko uruchomiÄ‡ projekt:

### Option 1: Enhanced Script (Rekomendowane)
```bash
# WyczyÅ›Ä‡ obecne zasoby
./scripts/deploy.sh cleanup

# SprÃ³buj ponownie z diagnostykÄ…
./scripts/deploy.sh troubleshoot
./scripts/deploy.sh deploy
```

### Option 2: Alternative KIND Deployment
```bash
# WyczyÅ›Ä‡ K3s
./scripts/deploy.sh cleanup

# Zainstaluj KIND (jeÅ›li nie masz)
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# Deploy z KIND
./scripts/deploy.sh deploy kind
```

### Option 3: Docker Compose (Najszybsze)
```bash
# WyczyÅ›Ä‡ wszystko
./scripts/deploy.sh cleanup

# Deploy z Docker Compose (bez Kubernetes)
./scripts/deploy.sh deploy local
```

## ğŸ” Diagnoza problemÃ³w K3s

SprawdÅº co siÄ™ dzieje:

```bash
# 1. Status kontenera K3s
docker ps -a | grep k3s
docker logs k3s-server

# 2. Zasoby systemowe
free -h
df -h
docker system df

# 3. Porty w uÅ¼yciu
netstat -tuln | grep -E ':(6443|8080|8443)'

# 4. WyczyÅ›Ä‡ Docker cache
docker system prune -f
docker volume prune -f
```

## ğŸ¯ Typowe przyczyny problemÃ³w K3s

### 1. NiewystarczajÄ…ce zasoby
```bash
# SprawdÅº dostÄ™pnÄ… pamiÄ™Ä‡
free -h
# Potrzebujesz minimum 4GB

# SprawdÅº miejsce na dysku  
df -h /var/lib/docker
# Potrzebujesz minimum 10GB
```

### 2. Konflikt portÃ³w
```bash
# SprawdÅº czy porty sÄ… wolne
sudo netstat -tuln | grep -E ':(6443|8080|8443|30080|30090|30030)'

# Zabij procesy uÅ¼ywajÄ…ce portÃ³w
sudo lsof -ti:6443 | xargs kill -9
```

### 3. Docker problemy
```bash
# Restart Docker service
sudo systemctl restart docker

# SprawdÅº status
sudo systemctl status docker
docker version
```

## ğŸš€ Szybkie rozwiÄ…zanie (Docker Compose)

JeÅ›li K3s nadal nie dziaÅ‚a, uÅ¼yj Docker Compose:

### 1. StwÃ³rz docker-compose.yml
```yaml
version: '3.8'
services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11435:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11435

  onnx-runtime:
    image: mcr.microsoft.com/onnxruntime/server:latest
    ports:
      - "8001:8001"

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin

volumes:
  ollama_data:
```

### 2. Uruchom
```bash
docker-compose up -d
docker-compose ps
```

### 3. Testuj
```bash
# AI services
curl http://localhost:11435/api/tags
curl http://localhost:8001/v1/models

# Monitoring
open http://localhost:9090  # Prometheus
open http://localhost:3000  # Grafana (admin/admin)
```

## ğŸ¬ Demo dla recruiters

Nawet z Docker Compose moÅ¼esz pokazaÄ‡:

### 1. Infrastructure as Code
```bash
# PokaÅ¼ terraform/main.tf
cat terraform/main.tf

# WyjaÅ›nij: "To normalnie deployuje K3s cluster, 
# ale dla demo uÅ¼yjÄ™ Docker Compose dla szybkoÅ›ci"
```

### 2. AI Integration
```bash
# Test Ollama LLM
curl -X POST http://localhost:11435/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "llama3.2:1b", "prompt": "Hello AI!"}'

# Test ONNX Runtime
curl http://localhost:8001/v1/models
```

### 3. Monitoring
```bash
# PokaÅ¼ Grafana dashboard
open http://localhost:3000

# PokaÅ¼ Prometheus metrics
open http://localhost:9090
```

### 4. Code Quality
```bash
# PokaÅ¼ deklaratywne pliki
ls -la k8s/
cat k8s/ai-platform.yaml | head -50
cat configs/Modelfile
```

## ğŸ’¡ Komunikat dla recruiters

> "Ten projekt demonstruje Infrastructure as Code patterns. 
> K3s normalnie deployuje siÄ™ w minutÄ™, ale dla demo uÅ¼yjÄ™ 
> Docker Compose Å¼eby pokazaÄ‡ funkcjonalnoÅ›Ä‡ szybciej. 
> W produkcji uÅ¼ywaÅ‚bym peÅ‚nego Kubernetes cluster."

## ğŸ”§ NastÄ™pne kroki

1. **Immediate**: UÅ¼yj Docker Compose dla demo
2. **Investigation**: Debug K3s issue w tle
3. **Improvement**: Dodaj alternative deployment methods
4. **Documentation**: Update README z troubleshooting

## ğŸ“ Emergency Contact

JeÅ›li nic nie dziaÅ‚a:

```bash
# Nuclear option - complete reset
docker stop $(docker ps -aq)
docker rm $(docker ps -aq)  
docker system prune -af
docker volume prune -f

# Start from scratch
./scripts/deploy.sh deploy local
```

